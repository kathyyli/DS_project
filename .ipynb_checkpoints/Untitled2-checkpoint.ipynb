{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qusac\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\qusac\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flask\n",
    "from flask import Flask, request\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "def api():\n",
    "    print('api processing')\n",
    "    if request.is_json:\n",
    "        input_data = request.get_json()\n",
    "    else:\n",
    "        # if not json post, return.\n",
    "        return ''\n",
    "    \n",
    "    # debug input json data.\n",
    "        print(input_data)\n",
    "\n",
    "        Y_prediction = None\n",
    "        try:\n",
    "            Y_prediction = prediction(input_data['song_name'],\n",
    "                        input_data['genre'],\n",
    "                        float(input_data['latitude']),\n",
    "                        float(input_data['longtitude']),\n",
    "                        float(input_data['bit_rate']),\n",
    "                        float(input_data['duration']),\n",
    "                        float(input_data['acousticness']),\n",
    "                        float(input_data['danceability']),\n",
    "                        float(input_data['energy']),\n",
    "                        float(input_data['instrumentalness']),\n",
    "                        float(input_data['liveness']),\n",
    "                        float(input_data['speechiness']),\n",
    "                        float(input_data['tempo']),\n",
    "                        float(input_data['valence']),\n",
    "                        float(input_data['artist_h']))\n",
    "        except Exception as ex:\n",
    "            Y_prediction = 'Exception raised'\n",
    "\n",
    "        if isinstance(Y_prediction, str):\n",
    "            _output_data = {'result': Y_prediction}\n",
    "        else:\n",
    "            print(type(Y_prediction))\n",
    "            _output_data = {'result': str(int(Y_prediction[0]))}\n",
    "\n",
    "        # 0 to 'Not popular' and 1 to 'Popular'.\n",
    "        output_data = _output_data\n",
    "        if _output_data['result'] == '0':\n",
    "            output_data['result'] = 'Not popular'\n",
    "        elif _output_data['result'] == '1':\n",
    "            output_data['result'] = 'Popular'\n",
    "        else:\n",
    "            pass\n",
    "         # This is the REST response.\n",
    "        response = flask.make_response(json.JSONEncoder().encode(output_data))\n",
    "        response.headers['content-type'] = 'application/json'\n",
    "        return response\n",
    "\n",
    "def prediction(genre,latitude, longitude, bit_rate, duration, acousticness, danceability,energy,instrumentalness,liveness, speechiness,tempo, valence,artist_hotttnesss,song_name):\n",
    "    \n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(song_name)\n",
    "    senti_neg=ss['neg']\n",
    "    senti_pos=ss['pos']\n",
    "    newline=pd.DataFrame({'latitude':latitude, 'longitude':longitude, 'bit_rate':bit_rate, 'duration':duration, 'acousticness':acousticness,\n",
    "            'danceability':danceability, 'energy':energy, 'instrumentalness':instrumentalness,'liveness':liveness,\n",
    "             'speechiness':speechiness,'tempo':tempo, 'valence':valence,'artist_hotttnesss':artist_hotttnesss,\n",
    "             'senti neg':senti_neg,'senti pos':senti_pos}, index=[372])\n",
    "    \n",
    "    \n",
    "    if genre == 'Rock':\n",
    "        df = pd.read_csv('Rock_10.csv', dtype=float)\n",
    "        df.drop(['track_ID','track_listens', 'artist_discovery','artist_familiarity'],axis=1,inplace=True)\n",
    "        \n",
    "        y=df[['popular']].values.ravel()\n",
    "        df1 = pd.concat([df,newline])\n",
    "\n",
    "        X=df1.drop(['popular'],axis=1)\n",
    "\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_train = X_scaled[:-1,:]\n",
    "        X_test = X_scaled[-1,:].reshape(1, -1)\n",
    "        \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X_train, y, test_size=0.2, random_state=7)\n",
    "        # Regularize over L1 penalty \n",
    "        C_vals = np.logspace(-4,0,100)\n",
    "        scores = []\n",
    "        for C_val in C_vals:\n",
    "\n",
    "            #change penalty to l1\n",
    "            regr = LogisticRegression(penalty='l1', C = C_val)\n",
    "            regr.fit(x_train, y_train)\n",
    "\n",
    "            probas_ = regr.fit(x_train, y_train).predict_proba(x_test)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            scores.append(roc_auc)\n",
    "\n",
    "        C_best_L1 = C_vals[scores.index(max(scores))]\n",
    "  \n",
    "        regr = LogisticRegression(penalty='l1',C=C_best_L1)\n",
    "        regr.fit(X_train, y)\n",
    "\n",
    "\n",
    "        Y_prediction = regr.predict(X_test)\n",
    "    if genre == 'Hiphop':\n",
    "        df = pd.read_csv('Hiphop_10.csv', dtype=float)\n",
    "        df.drop(['track_ID','track_listens', 'artist_discovery','artist_familiarity'],axis=1,inplace=True)\n",
    "        \n",
    "        y=df[['popular']].values.ravel()\n",
    "        df1 = pd.concat([df,newline])\n",
    "\n",
    "        X=df1.drop(['popular'],axis=1)\n",
    "\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_train = X_scaled[:-1,:]\n",
    "        X_test = X_scaled[-1,:].reshape(1, -1)\n",
    "        \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X_train, y, test_size=0.2, random_state=7)\n",
    "        # Regularize over L1 penalty \n",
    "        C_vals = np.logspace(-4,0,100)\n",
    "        scores = []\n",
    "        for C_val in C_vals:\n",
    "\n",
    "            #change penalty to l1\n",
    "            regr = LogisticRegression(penalty='l1', C = C_val)\n",
    "            regr.fit(x_train, y_train)\n",
    "\n",
    "            probas_ = regr.fit(x_train, y_train).predict_proba(x_test)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            scores.append(roc_auc)\n",
    "\n",
    "        C_best_L1 = C_vals[scores.index(max(scores))]\n",
    "  \n",
    "        regr = LogisticRegression(penalty='l1',C=C_best_L1)\n",
    "        regr.fit(X_train, y)\n",
    "\n",
    "\n",
    "        Y_prediction = regr.predict(X_test)\n",
    "    if genre == 'Electronic':\n",
    "        df = pd.read_csv('Elec_10.csv', dtype=float)\n",
    "        df.drop(['track_ID','track_listens', 'artist_discovery','artist_familiarity'],axis=1,inplace=True)\n",
    "        \n",
    "        y=df[['popular']].values.ravel()\n",
    "        df1 = pd.concat([df,newline])\n",
    "\n",
    "        X=df1.drop(['popular'],axis=1)\n",
    "\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        X_train = X_scaled[:-1,:]\n",
    "        X_test = X_scaled[-1,:].reshape(1, -1)\n",
    "        \n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X_train, y, test_size=0.2, random_state=7)\n",
    "        # Regularize over L1 penalty \n",
    "        C_vals = np.logspace(-4,0,100)\n",
    "        scores = []\n",
    "        for C_val in C_vals:\n",
    "\n",
    "            #change penalty to l1\n",
    "            regr = LogisticRegression(penalty='l1', C = C_val)\n",
    "            regr.fit(x_train, y_train)\n",
    "\n",
    "            probas_ = regr.fit(x_train, y_train).predict_proba(x_test)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            scores.append(roc_auc)\n",
    "\n",
    "        C_best_L1 = C_vals[scores.index(max(scores))]\n",
    "  \n",
    "        regr = LogisticRegression(penalty='l1',C=C_best_L1)\n",
    "        regr.fit(X_train, y)\n",
    "\n",
    "\n",
    "        Y_prediction = regr.predict(X_test)\n",
    "    return(Y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
