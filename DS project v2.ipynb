{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import pylab as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import librosa  #need install first\n",
    "#import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rulanxiao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/rulanxiao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,11,13,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load metadata and features.\n",
    "tracks = pd.read_csv('/Users/rulanxiao/Desktop/fma_metadata/tracks.csv', header=None)\n",
    "echonest = pd.read_csv('/Users/rulanxiao/Desktop/fma_metadata/echonest.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names from \"track.1\", ... to named columns\n",
    "header = tracks.iloc[1]\n",
    "header[0] = 'track_ID'\n",
    "tracks.drop(tracks.index[[0,1,2]], inplace=True)\n",
    "tracks.rename(columns=header, inplace=True)\n",
    "tracks.head()\n",
    "\n",
    "header = echonest.iloc[2]\n",
    "header[0]='track_ID'\n",
    "echonest.drop(echonest.index[[0,1,2,3]],inplace=True)\n",
    "echonest.rename(columns = header,inplace=True)\n",
    "echonest.head()\n",
    "\n",
    "# Only select songs for which we have echonest data\n",
    "tracks_with_echonest_data = tracks[tracks['track_ID'].isin(echonest['track_ID'])]\n",
    "echonest_data = echonest[echonest['track_ID'].isin(tracks_with_echonest_data['track_ID'])]\n",
    "\n",
    "merged_echonest_data = pd.merge(tracks_with_echonest_data, echonest_data, on = 'track_ID')\n",
    "\n",
    "# Change duplicate \"listens\" column to track listens and album listens\n",
    "duplicate_listens = {'listens': ['album_listens', 'track_listens']}\n",
    "\n",
    "merged_echonest_data = merged_echonest_data.rename(columns=lambda c: duplicate_listens[c].pop(0) if c in duplicate_listens.keys() else c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({nan: 3140, '2010': 1461, '2009': 1426, '2011': 1101, '2008': 1088, '2007': 464, '2012': 380, '2006': 346, '2013': 298, '2014': 245, '2004': 167, '2005': 150, '2015': 145, '2003': 94, '2002': 84, '2001': 69, '1999': 68, '2000': 34, '1997': 25, '1995': 20, '1982': 19, '1998': 17, '1996': 10, '1986': 10, '1981': 6, '1973': 5, '1985': 5, '1992': 3, '1913': 2, '1976': 2, '1912': 1, '1916': 1, '1911': 1, '1909': 1, '1905': 1, '1907': 1, '1988': 1, '1902': 1})\n",
      "dict_values([1426, 1088, 464, 150, 20, 346, 3140, 94, 19, 6, 69, 84, 167, 34, 68, 10, 1, 1, 1, 2, 1, 1, 1, 25, 3, 1, 17, 1461, 2, 10, 1101, 5, 245, 380, 298, 5, 1, 145])\n",
      "dict_keys(['2009', '2008', '2007', '2005', '1995', '2006', nan, '2003', '1982', '1981', '2001', '2002', '2004', '2000', '1999', '1996', '1912', '1916', '1911', '1913', '1909', '1905', '1907', '1997', '1992', '1988', '1998', '2010', '1976', '1986', '2011', '1973', '2014', '2012', '2013', '1985', '1902', '2015'])\n",
      "[(nan, 3140), ('2010', 1461), ('2009', 1426)]\n"
     ]
    }
   ],
   "source": [
    "# Extract year released from release date variable\n",
    "album_release_year = []\n",
    "\n",
    "for x in merged_echonest_data['date_released']:\n",
    "    if type(x)==str:\n",
    "        album_release_year.append(x[0:4])\n",
    "    else: \n",
    "        album_release_year.append(np.nan)\n",
    "\n",
    "#add album release year to dataframe\n",
    "merged_echonest_data['album_release_year'] = album_release_year\n",
    "\n",
    "# Check number of songs released per year and pick year with maximum\n",
    "import collections\n",
    "counter=collections.Counter(album_release_year)\n",
    "print(counter)\n",
    "print(counter.values())\n",
    "print(counter.keys())\n",
    "print(counter.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({nan: 524, 'Rock': 372, 'Electronic': 271, 'Hip-Hop': 133, 'Folk': 67, 'Pop': 58, 'Jazz': 23, 'International': 12, 'Instrumental': 1})\n",
      "dict_values([23, 372, 58, 271, 524, 133, 67, 12, 1])\n",
      "dict_keys(['Jazz', 'Rock', 'Pop', 'Electronic', nan, 'Hip-Hop', 'Folk', 'International', 'Instrumental'])\n",
      "[(nan, 524), ('Rock', 372), ('Electronic', 271), ('Hip-Hop', 133), ('Folk', 67), ('Pop', 58), ('Jazz', 23), ('International', 12), ('Instrumental', 1)]\n"
     ]
    }
   ],
   "source": [
    "# For chosen year, check the number of songs released per genre; pick top three genres to use\n",
    "tracks_2010 = merged_echonest_data[merged_echonest_data['album_release_year'] == '2010']\n",
    "\n",
    "# Top genres for 2010\n",
    "counter=collections.Counter(tracks_2010['genre_top'])\n",
    "print(counter)\n",
    "print(counter.values())\n",
    "print(counter.keys())\n",
    "print(counter.most_common(10))\n",
    "\n",
    "# Remove NAs, if needed \n",
    "\n",
    "# Select sensical variables from merged dataset (i.e., some track metadata and named echonest features)\n",
    "\n",
    "# Stuff above - Kathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rulanxiao/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rulanxiao/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Add sentiment analysis by title into dataset - compound score of positive / negative sentiment for song title\n",
    "# Rulan\n",
    "# require to install nltk first\n",
    "# this part work nice, file will be generated to our project folder. \n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "tracks_senti = pd.read_csv('/Users/rulanxiao/Desktop/fma_metadata/tracks.csv',header=None)\n",
    "\n",
    "header = tracks_senti.iloc[1]\n",
    "header[0]='track ID'\n",
    "header[52]='track title'\n",
    "tracks_senti.drop(tracks_senti.index[[0,1,2]],inplace=True)\n",
    "tracks_senti.rename(columns = header,inplace=True)\n",
    "tracks_senti.head()\n",
    "\n",
    "df=tracks_senti[['track ID','track title']]\n",
    "df.dropna(axis=0, how='any')\n",
    "\n",
    "ml = df[\"track title\"].values\n",
    "title=[]\n",
    "for i in range(len(ml)):\n",
    "    a=str(ml[i])\n",
    "    title.append(a)\n",
    "idd = df[\"track ID\"].values\n",
    "\n",
    "neg=[]\n",
    "neu=[]\n",
    "pos=[]\n",
    "comp=[]\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in title:\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    score=[]\n",
    "    for k in ss:\n",
    "        a=ss[k]\n",
    "        score.append(a)\n",
    "    neg.append(score[0])\n",
    "    neu.append(score[1])\n",
    "    pos.append(score[2])\n",
    "    comp.append(score[3])\n",
    "\n",
    "sentimentall = pd.DataFrame({'track_ID':idd,'track_title':title,'senti neg': neg,'senti neu': neu,'senti pos': pos,'senti comp': comp})\n",
    "\n",
    "sentimentall.to_csv('sentimental_analysis_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment= pd.read_csv('sentimental_analysis_title.csv', header=[0])\n",
    "#sentiment.rename(index=str, columns={'track_ID' : 'track ID'},inplace=True)\n",
    "sentiment=sentiment[['track_ID','senti comp', 'senti neg','senti pos']]\n",
    "tracks_2010 = pd.merge(tracks_2010, sentiment, how='inner', on=['track_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For baseline model - add genre as a categorical variable \n",
    "# Sa\n",
    "\n",
    "t10 = tracks_2010[['track_ID','latitude','longitude','bit_rate','duration','genre_top','genres_all','track_listens','acousticness','danceability','energy','instrumentalness','liveness','speechiness','tempo','valence','artist_hotttnesss','senti comp', 'senti neg','senti pos']]\n",
    "t10['Rock'] = (t10['genre_top'] == 'Rock').astype(int)\n",
    "t10['Hip-Hop'] = (t10['genre_top'] == 'Hip-Hop').astype(int)\n",
    "t10['Electronic'] = (t10['genre_top'] == 'Electronic').astype(int)\n",
    "\n",
    "# For genre-specific models - split dataset into three based on top three genres\n",
    "# Sa\n",
    "\n",
    "t10.groupby(['genre_top']).size()\n",
    "Hiphop_10=t10.loc[t10['genre_top'] == 'Hip-Hop']\n",
    "Rock_10=t10.loc[t10['genre_top'] == 'Rock']\n",
    "Elec_10=t10.loc[t10['genre_top'] == 'Electronic']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 15)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-081885ad2107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bit_rate'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'duration'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'track_listens'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'acousticness'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'danceability'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'energy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'instrumentalness'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'liveness'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'speechiness'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tempo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'artist_hotttnesss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'senti comp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'senti neg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'senti pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Repeat for other two genres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rulanxiao/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rulanxiao/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rulanxiao/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rulanxiao/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    414\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 416\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 15)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# Make boxplots of variables in genre dataset \n",
    "# Sa\n",
    "t10.boxplot()\n",
    "# Standardize variables as needed\n",
    "# Sa\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = np.array(t10[['track_listens']].values)\n",
    "X=(t10[['bit_rate','duration','track_listens','acousticness','danceability','energy','instrumentalness','liveness','speechiness','tempo','valence','artist_hotttnesss','senti comp', 'senti neg','senti pos']].values)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "# Repeat for other two genres\n",
    "# Sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_ID</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>duration</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres_all</th>\n",
       "      <th>track_listens</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist_hotttnesss</th>\n",
       "      <th>senti comp</th>\n",
       "      <th>senti neg</th>\n",
       "      <th>senti pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [track_ID, latitude, longitude, bit_rate, duration, genre_top, genres_all, track_listens, acousticness, danceability, energy, instrumentalness, liveness, speechiness, tempo, valence, artist_hotttnesss, senti comp, senti neg, senti pos]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for correlation between variables with correlation plot \n",
    "# Kathy\n",
    "\n",
    "# Check for correlation between arist hotness, familiarity, discovery\n",
    "# Kathy\n",
    "t10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-f89499530198>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-f89499530198>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    scatter_matrix(??,figsize=(30,30))\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Make scatter plots of numerical variables versus outcome (track listens)\n",
    "# Rulan\n",
    "\n",
    "plt.scatter(tracks.track_listens,tracks.acousticness)\n",
    "plt.ylabel('track_listens')\n",
    "plt.xlabel('duration')\n",
    "plt.title('track_listens v.s. duration')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(t10.track_listens,t10.acousticness)\n",
    "plt.ylabel('track_listens')\n",
    "plt.xlabel('acousticness')\n",
    "plt.title('track_listens v.s. acousticness')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(t10.track_listens,t10.acousticness)\n",
    "plt.ylabel('track_listens')\n",
    "plt.xlabel('energy')\n",
    "plt.title('track_listens v.s. energy')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(t10.track_listens,t10.acousticness)\n",
    "plt.ylabel('track_listens')\n",
    "plt.xlabel('instrumentalness')\n",
    "plt.title('track_listens v.s. instrumentalness')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(t10.track_listens,t10.acousticness)\n",
    "plt.ylabel('track_listens')\n",
    "plt.xlabel('liveness')\n",
    "plt.title('track_listens v.s. liveness')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(t10.track_listens,t10.acousticness)\n",
    "plt.ylabel('track_listens')\n",
    "plt.xlabel('speechiness')\n",
    "plt.title('track_listens v.s. speechiness')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(t10.track_listens,t10.acousticness)\n",
    "plt.ylabel('track_listens')\n",
    "plt.xlabel('tempo')\n",
    "plt.title('track_listens v.s. tempo')\n",
    "plt.show()\n",
    "\n",
    "scatter_matrix(??,figsize=(30,30))\n",
    "plt.show()\n",
    "\n",
    "# Correlation plots for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model - use the year with most songs data and include genre as a categorical variable (use the same top 3 genres)\n",
    "\n",
    "# Convert genre to dummy variables\n",
    "\n",
    "# Use linear regression with same variables as above (sentiment analysis, track metadata, echonest named variable, location)\n",
    "\n",
    "# IDEA: we will see that genre is a big predictor of track listens - thus, we train separate models for each genre to dig deeper into why that is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 5-folds, split data into training and testing (one of the genres) - will repeat for other two genres (maybe write function to do this)\n",
    "\n",
    "# Train linear regression model using all variables\n",
    "\n",
    "# Regularize using L^1 penalty due to large number of features - pick optimal penalty and compare R^2\n",
    "\n",
    "# Use GridSearchCV with at least 2-fold validation\n",
    "\n",
    "# Check resulting model on 5 random folds of data \n",
    "\n",
    "# Plot coefficients for resulting model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train random forest regression model \n",
    "\n",
    "# Regularize using L^1 penalty due to large number of features - pick optimal penalty and compare R^2\n",
    "\n",
    "# Use GridSearchCV with at least 2-fold validation\n",
    "\n",
    "# Check resulting model on 5 random folds of data \n",
    "\n",
    "# Plot coefficients for resulting model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore adding other features to model, such as nonlinear features (interaction terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hip hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare how models are different between different genres - for instance, if certain variables are more or less important for different genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function that takes in optimal_model, new song audio and necessary info (like genre, track title, etc.) and uses librosa to extract features\n",
    "# and output a prediction of number of track listens \n",
    "\n",
    "# Load the example clip\n",
    "# Load 30 seconds of a wav file, starting 15 seconds in\n",
    "y, sr = librosa.load('blahblah.mp3', offset=15.0, duration=30.0)\n",
    "\n",
    "# Set the hop length; at 22050 Hz, 512 samples ~= 23ms\n",
    "hop_length = 512\n",
    "\n",
    "# Separate harmonics and percussives into two waveforms\n",
    "y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "# Beat track on the percussive signal\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y_percussive,\n",
    "                                             sr=sr)\n",
    "\n",
    "# Compute MFCC features from the raw signal\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "\n",
    "# And the first-order differences (delta features)\n",
    "mfcc_delta = librosa.feature.delta(mfcc)\n",
    "\n",
    "# Stack and synchronize between beat events\n",
    "# This time, we'll use the mean value (default) instead of median\n",
    "beat_mfcc_delta = librosa.util.sync(np.vstack([mfcc, mfcc_delta]),\n",
    "                                    beat_frames)\n",
    "\n",
    "# Compute chroma features from the harmonic signal\n",
    "chromagram = librosa.feature.chroma_cqt(y=y_harmonic,\n",
    "                                        sr=sr)\n",
    "\n",
    "# Aggregate chroma features between beat events\n",
    "# We'll use the median value of each feature between beat frames\n",
    "beat_chroma = librosa.util.sync(chromagram,\n",
    "                                beat_frames,\n",
    "                                aggregate=np.median)\n",
    "\n",
    "# Finally, stack all beat-synchronous features together\n",
    "beat_features = np.vstack([beat_chroma, beat_mfcc_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Statistic for each feature\n",
    "def columns():\n",
    "    feature_sizes = dict(chroma_stft=12, chroma_cqt=12, chroma_cens=12,\n",
    "                         tonnetz=6, mfcc=20, rmse=1, zcr=1,\n",
    "                         spectral_centroid=1, spectral_bandwidth=1,\n",
    "                         spectral_contrast=7, spectral_rolloff=1)\n",
    "    moments = ('mean', 'std', 'skew', 'kurtosis', 'median', 'min', 'max')\n",
    "\n",
    "    columns = []\n",
    "    for name, size in feature_sizes.items():\n",
    "        for moment in moments:\n",
    "            it = ((name, moment, '{:02d}'.format(i+1)) for i in range(size))\n",
    "            columns.extend(it)\n",
    "\n",
    "    names = ('feature', 'statistics', 'number')\n",
    "    columns = pd.MultiIndex.from_tuples(columns, names=names)\n",
    "\n",
    "    # More efficient to slice if indexes are sorted.\n",
    "    return columns.sort_values()\n",
    "\n",
    "\n",
    "def feature_stats(name, values):\n",
    "    features[name, 'mean'] = np.mean(values, axis=1)\n",
    "    features[name, 'std'] = np.std(values, axis=1)\n",
    "    features[name, 'skew'] = stats.skew(values, axis=1)\n",
    "    features[name, 'kurtosis'] = stats.kurtosis(values, axis=1)\n",
    "    features[name, 'median'] = np.median(values, axis=1)\n",
    "    features[name, 'min'] = np.min(values, axis=1)\n",
    "    features[name, 'max'] = np.max(values, axis=1)\n",
    "\n",
    "\n",
    "features = pd.Series(index=columns(), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##OTHER FEATURES\n",
    "y, sr = librosa.load('Rough & Laugh.mp3', offset=15.0, duration=30.0)\n",
    "\n",
    "stft=np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\n",
    "f = librosa.feature.chroma_stft(S=stft**2, n_chroma=12)\n",
    "feature_stats('chroma_stft', f)\n",
    "\n",
    "f = librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=512)\n",
    "feature_stats('zcr', f)\n",
    "\n",
    "cqt = np.abs(librosa.cqt(y, sr=sr, hop_length=512, bins_per_octave=12,\n",
    "                                 n_bins=7*12, tuning=None))\n",
    "assert cqt.shape[0] == 7 * 12\n",
    "assert np.ceil(len(y)/512) <= cqt.shape[1] <= np.ceil(len(y)/512)+1\n",
    "\n",
    "\n",
    "f = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
    "feature_stats('chroma_cqt', f)\n",
    "\n",
    "f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "feature_stats('chroma_cens', f)\n",
    "\n",
    "f = librosa.feature.tonnetz(chroma=f)\n",
    "feature_stats('tonnetz', f)\n",
    "\n",
    "print(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
